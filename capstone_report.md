# 机器学习纳米学位
## 毕业项目
 Joe Huang 优达学城 

2018年11月20日


## I. 问题的定义

随着互联网与社交媒体的发展，恶毒评论在各大论坛网站层出不穷，如虎扑、Facebook等。对恶毒评论研究分类，可以对信息进行筛选，可以有效的清理网络环境。其中最基本的是对恶毒评论进行甄别，这里用到的主要技术是自然语言处理。

自然语言处理方向（简称NLP），是机器学习中十分热门的一个方向。据维基百科所述，NLP是计算机科学、信息工程和人工只能的重要领域，是计算机与人类语言交互的重要手段，它通常包括认知、理解和生成等部分。其中认知和理解是电脑将输入的语言变成特定的符号，生成则是将计算机数据转化成自然语言。

同其他机器学习领域类似，自然语言的起源也很早，早在上世纪50年代就被伟大计算机科学界艾伦-麦席森-图灵所提及，但却局限于当时的计算水平而无法真正意义上的普及。著名的“图灵测试”就是当时被提出，这是一项判断机器语言与自然语言的标准。2018年google IO大会上推出的google assistant，迄今最有可能通过该测试。

自然语言的处理范畴很多，包括文本朗读（Text to speech）/语音合成（Speech synthesis），语言识别（Speech recognition），语法分析（Parsing）、自然语言生成（Natural language generation）和文本分类（Text categorization）等等。较大众所熟知的多为语言识别类，而本毕业项目“恶毒评论分类”则属于文本分类范畴。

### 项目概述

项目名称: Toxic Comment Classification（恶毒评论分类）

恶毒评论项目源于Jigsaw(前身为Google ideas）在kaggle平台上举办的一场文本分类比赛[1]，旨在对于网络社区部分恶毒评论进行区分鉴别。

文本分类是自然语言中比较普遍的应用，如文件邮件自动分类等，目前主要有传统机器学习和深度学习模型方法等。常见的处理流程包括：训练样本预处理、特征选择、计算特征权重得到文本向量和模型训练与预测。

输入数据如下：kaggle中提供的数据包括4部分：train，test，sample_submission，test_lables。

train训练数据总量约160k，包含1个id行和7个标签数据，见下图。数据的分布为非均匀分布，并且每个数据可能对应多个标签，其中clean语句的分布最多，约为87%。toxic语句约为9.5%，obscence语句约为5.3%，insult语句约为4.9%，severe-toxic语句约为1%，identity_hate语句约为0.88%，treat语句最少，约为0.3%。

test和test_lable为测试数据及标签，总量约为150k。test数据只包含id，comment_text，output需要输出分类概率。

### 问题陈述
本项目需要解决的是自然语言文本分类问题，根绝训练集数据，包括toxic、obscence、severe-toxic、identity_hate和treat六个类型的文本语言，项目需要对其进行训练，以保持对测试集数据能够很好地分类，并输出概率，如下表所示。项目的重点难点在于合适的文本向量与合适的训练预测算法。

最终需要输出的标签概率，示例：

| id               | toxic | severe_toxic | obscene | threat | insult | identity_hate |
| ---------------- | ----- | ------------ | ------- | ------ | ------ | ------------- |
| 00001cee341fdb12 | 0.5   | 0.5          | 0.5     | 0.5    | 0.5    | 0.5           |

在这个部分，你需要清楚地为你将要解决的问题下定义，这应该包括你解决问题将要使用的策略（任务的大纲）。你同时要详尽地讨论你期望的结果是怎样的。有几个问题是需要考虑的：

### 评价指标
根据kaggle上的描述，采用ROC AUC评估矩阵方式，分数计算方式为每一个预测列的平均AUC值。

ROC曲线为True Positive Rate和False Positive Rate曲线图[8]。ROC曲线特性适用于当测试正负样本集变换时，ROC曲线能保持不变。对于实际数据中出现样本分类不平衡时，集正负样本比例比较大且随时间变化时，ROC曲线基本保持不变。AUC（Area Under Curve），即ROC曲线下方面积，介于0.1-1。AUC值越趋向1，分类器效果越好。

ROC-AUC概念图如下：

![](pics/ROC_curves.svg.png)

在这里，你需要说明你将要用于评价自己的模型和结果的**指标**和**计算方法**。它们需要契合你所选问题的特点及其所在的领域，同时，你要保证他们的合理性。需要考虑的问题：

- _你是否清晰地定义了你所使用的指标和计算方法？_
- _你是否论述了这些指标和计算方法的合理性？_


## II. 分析
_(大概 2-4 页)_

### 数据的探索
根据kaggle提供的数据，下面展示train数据集前10行数据。

数据集包括id、comment_text、6个类别，0和1表示语句对应的标签值，一个语句可以对应有多个分类。若每个类别对应的标签值均为0，表示该语句为clean。显然，clean语句占大部分文本内容。

- train具体数据前10行。

| id               | comment_text                                      | toxic | severe_toxic | obscene | threat | insult | identity_hate |
| ---------------- | ------------------------------------------------- | ----- | ------------ | ------- | ------ | ------ | ------------- |
| 0000997932d777bf | Explanation\nWhy the edits made under my usern... | 0     | 0            | 0       | 0      | 0      | 0             |
| 000103f0d9cfb60f | D'aww! He matches this background colour I'm s... | 0     | 0            | 0       | 0      | 0      | 0             |
| 000113f07ec002fd | Hey man, I'm really not trying to edit war. It... | 0     | 0            | 0       | 0      | 0      | 0             |
| 0001b41b1c6bb37e | "\nMore\nI can't make any real suggestions on ... | 0     | 0            | 0       | 0      | 0      | 0             |
| 0001d958c54c6e35 | You, sir, are my hero. Any chance you remember... | 0     | 0            | 0       | 0      | 0      | 0             |
| 00025465d4725e87 | "\n\nCongratulations from me as well, use the ... | 0     | 0            | 0       | 0      | 0      | 0             |
| 0002bcb3da6cb337 | COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      | 1     | 1            | 1       | 0      | 1      | 0             |
| 00031b1e95af7921 | Your vandalism to the Matt Shirvington article... | 0     | 0            | 0       | 0      | 0      | 0             |
| 00037261f536c51d | Sorry if the word 'nonsense' was offensive to ... | 0     | 0            | 0       | 0      | 0      | 0             |
| 00040093b2687caa | alignment on this subject and which are contra... | 0     | 0            | 0       | 0      | 0      | 0             |

- train数据统计如下表所示：

train数据共计159571行语句，根据语句标签可以得到各个类别的概率统计值。

|       | toxic         | severe_toxic  | obscene       | threat        | insult        | identity_hate |
| ----- | ------------- | ------------- | ------------- | ------------- | ------------- | ------------- |
| count | 159571.000000 | 159571.000000 | 159571.000000 | 159571.000000 | 159571.000000 | 159571.000000 |
| mean  | 0.095844      | 0.009996      | 0.052948      | 0.002996      | 0.049364      | 0.008805      |
| std   | 0.294379      | 0.099477      | 0.223931      | 0.054650      | 0.216627      | 0.093420      |
| min   | 0.000000      | 0.000000      | 0.000000      | 0.000000      | 0.000000      | 0.000000      |
| 25%   | 0.000000      | 0.000000      | 0.000000      | 0.000000      | 0.000000      | 0.000000      |
| 50%   | 0.000000      | 0.000000      | 0.000000      | 0.000000      | 0.000000      | 0.000000      |
| 75%   | 0.000000      | 0.000000      | 0.000000      | 0.000000      | 0.000000      | 0.000000      |
| max   | 1.000000      | 1.000000      | 1.000000      | 1.000000      | 1.000000      | 1.000000      |

- train数据分图形展示：

  从图中可以看出，clean语句远远大于其它语句，约为87%。toxic语句约为9.5%，obscence语句约为5.3%，insult语句约为4.9%，severe-toxic语句约为1%，identity_hate语句约为0.88%，treat语句最少，约为0.3%。

![训练数据](pics/hist.png "train数据分布")

在这一部分，你需要探索你将要使用的数据。数据可以是若干个数据集，或者输入数据/文件，甚至可以是一个设定环境。你需要详尽地描述数据的类型。如果可以的话，你需要展示数据的一些统计量和基本信息（例如输入的特征（features)，输入里与定义相关的特性，或者环境的描述）。你还要说明数据中的任何需要被关注的异常或有趣的性质（例如需要做变换的特征，离群值等等）。你需要考虑：

- _如果你使用了数据集，你要详尽地讨论了你所使用数据集的某些特征，并且为阅读者呈现一个直观的样本_
- _如果你使用了数据集，你要计算并描述了它们的统计量，并对其中与你问题相关的地方进行讨论_
- _如果你**没有**使用数据集，你需要对你所使用的输入空间（input space)或输入数据进行讨论？_
- _数据集或输入中存在的异常，缺陷或其他特性是否得到了处理？(例如分类变数，缺失数据，离群值等）_

### 探索性可视化

在这一部分，你需要对数据的特征或特性进行概括性或提取性的可视化。这个可视化的过程应该要适应你所使用的数据。就你为何使用这个形式的可视化，以及这个可视化过程为什么是有意义的，进行一定的讨论。你需要考虑的问题：
- _你是否对数据中与问题有关的特性进行了可视化？_
- _你对可视化结果进行详尽的分析和讨论了吗？_
- _绘图的坐标轴，标题，基准面是不是清晰定义了？_

### 算法和技术
算法主要采用（CNN + GRU）× 3三个模型进行特征提取。本项目将主要基于keras上的框架进行分析。

CNN，卷积神经网络。主要基于卷积运算，这是信号处理中十分常用的方式，可以对特征进行提取。在自然语言处理方面，它的优势在于能快速进行计算，在表征方面也更加有效[5]。在NLP自然语言文本分类，对于本项目包含情感的分类比较有效。

![](pics\Selection_004.png)

GRU即Gated Recurrent Unit，门限循环单元网络 。它是LSTM的变体，在保持LSTM效果的同时，其结果更加简单。通常认为，GRU具有较少的参数，所以训练速度快，而且所需要的样本也比较少。而LSTM具有较多的参数，比较适合具有大量样本的情况，可能会获得较优的模型。

GRU模型如下，它只有两个门了，分别为更新门和重置门，即图中的zt和rt。更新门用于控制前一时刻的状态信息被带入到当前状态中的程度，更新门的值越大说明前一时刻的状态信息带入越多。重置门用于控制忽略前一时刻的状态信息的程度，重置门的值越小说明忽略得越多。

GRU模型图示：

![](pics\Selection_003.png)

在算法训练完成后，需要对算法模型进行评估。应用算法对测试数据进行预测，并根据上文提及的ROC-AUC评估矩阵，对预测值进行评估。

在这一部分，你需要讨论你解决问题时用到的算法和技术。你需要根据问题的特性和所属领域来论述使用这些方法的合理性。你需要考虑：

- _你所使用的算法，包括用到的变量/参数都清晰地说明了吗？_
- _你是否已经详尽地描述并讨论了使用这些技术的合理性？_
- _你是否清晰地描述了这些算法和技术具体会如何处理这些数据？_

### 基准模型
自然语言算法模型分类大致分为传统方法和深度学习神经网络方法。传统方法主要是从原始文档提取特征，在制定分类器进行计算。经典特征提取方法如频次法、tf-idf、互信息法、Ngram，分类器算法如LR、SVM等。神经网络特征提取方法如CNN、RNN、LSTM等。基于传统方法tf-idf和LR算法已经可以很好地得到分类结果[6]，本项目将其作为benchmark model。

tf-idf为词频-逆文档频度（Term Frequency - Inverse Document Frequency，TF-IDF）。词频为语句在某一个给定的词语在该文件中出现的次数。逆文档频率是值出现给定词语的文件总数概率对数。该概念能够很好反应词语的重要性。

LR为逻辑回归，是传统机器学习的方式。

该model处理方法比较简单，先是提取数据中的文本资料，然后对统计tf-idf，将其转化成词词向量。最后用机器学习的方法对test数据集进行预测。相比与深度学习，该方法更加简单高效，并且能得到很高的预测分数，在一定条件下实用性高。

该模型有很好的效果，在kaggle上的得分约为0.97+.

![](pics\Selection_005.png)


## III. 方法
_(大概 3-5 页）_

### 数据预处理
数据挖掘分析，主要是采取可视化的方式对训练测试数据进行展示，如数据量大小、toxic comments与non-toxic comments的分布等。可以借助大数据词云显示等，分别展示toxic comments与non-toxic comments的较大词频词语的分布等，有助于本人了解不同分类语句之间的主要区别，也有助于下一步数据处理。

数据处理是主要包括数据预处理与主处理。

数据预处理主要是对数据进行清洗，去除一些训练测试数据中出现的空白、乱码词句、杂乱无章等非正常语句。

数据主处理主要是对语句进行处理，计算机无法识别自然语言，必须将其转换成机器语言。本项目中，需要将语句解析分成单独词字，再将词字转化成数值形式，并进行编码。这种形式称为word embedding[4]，常见手段有Glove、fastText、word2vec。杜热编码（One-Hot encoding）也是一种方式，但对任意词的余弦相似度都为0，但无法表达不同词之间的相似度。

对于自然语言处理而言，预训练词向量特别关键。本项目将采用glove.840B.300d作为预向量数据。

在这一部分， 你需要清晰记录你所有必要的数据预处理步骤。在前一个部分所描述的数据的异常或特性在这一部分需要被更正和处理。需要考虑的问题有：

- _如果你选择的算法需要进行特征选取或特征变换，你对此进行记录和描述了吗？_
- _**数据的探索**这一部分中提及的异常和特性是否被更正了，对此进行记录和描述了吗？_
- _如果你认为不需要进行预处理，你解释个中原因了吗？_

### 执行过程


在这一部分， 你需要描述你所建立的模型在给定数据上执行过程。模型的执行过程，以及过程中遇到的困难的描述应该清晰明了地记录和描述。需要考虑的问题：

- _你所用到的算法和技术执行的方式是否清晰记录了？_
- _在运用上面所提及的技术及指标的执行过程中是否遇到了困难，是否需要作出改动来得到想要的结果？_
- _是否有需要记录解释的代码片段(例如复杂的函数）？_

### 完善
![](pics\Selection_006.png)

在这一部分，你需要描述你对原有的算法和技术完善的过程。例如调整模型的参数以达到更好的结果的过程应该有所记录。你需要记录最初和最终的模型，以及过程中有代表性意义的结果。你需要考虑的问题：

- _初始结果是否清晰记录了？_
- _完善的过程是否清晰记录了，其中使用了什么技术？_
- _完善过程中的结果以及最终结果是否清晰记录了？_


## IV. 结果
_（大概 2-3 页）_

### 模型的评价与验证
在这一部分，你需要对你得出的最终模型的各种技术质量进行详尽的评价。最终模型是怎么得出来的，为什么它会被选为最佳需要清晰地描述。你也需要对模型和结果可靠性作出验证分析，譬如对输入数据或环境的一些操控是否会对结果产生影响（敏感性分析sensitivity analysis）。一些需要考虑的问题：
- _最终的模型是否合理，跟期待的结果是否一致？最后的各种参数是否合理？_
- _模型是否对于这个问题是否足够稳健可靠？训练数据或输入的一些微小的改变是否会极大影响结果？（鲁棒性）_
- _这个模型得出的结果是否可信？_

### 合理性分析
在这个部分，你需要利用一些统计分析，把你的最终模型得到的结果与你的前面设定的基准模型进行对比。你也分析你的最终模型和结果是否确确实实解决了你在这个项目里设定的问题。你需要考虑：
- _最终结果对比你的基准模型表现得更好还是有所逊色？_
- _你是否详尽地分析和讨论了最终结果？_
- _最终结果是不是确确实实解决了问题？_


## V. 项目结论
_（大概 1-2 页）_

### 结果可视化
| toxic            | severe_toxic | obscene      | threat   | insult   | identity_hate |          |
| ---------------- | ------------ | ------------ | -------- | -------- | ------------- | -------- |
| 00001cee341fdb12 | 0.995896     | 2.969470e-01 | 0.942868 | 0.017343 | 0.911473      | 0.656551 |
| 0000247867823ef7 | 0.000678     | 4.632167e-06 | 0.000070 | 0.000006 | 0.000047      | 0.000020 |
| 00013b17ad220c46 | 0.000564     | 1.628422e-05 | 0.000079 | 0.000010 | 0.000043      | 0.000024 |
| 00017563c3f7919a | 0.000104     | 1.008281e-06 | 0.000013 | 0.000002 | 0.000008      | 0.000003 |
| 00017695ad8997eb | 0.011499     | 8.669518e-05 | 0.001452 | 0.000169 | 0.000790      | 0.000254 |
| 0001ea8717f6de06 | 0.000247     | 1.319934e-06 | 0.000026 | 0.000004 | 0.000015      | 0.000006 |
| 00024115d4cbde0f | 0.002852     | 3.139631e-06 | 0.000137 | 0.000019 | 0.000112      | 0.000015 |
| 000247e83dcc1211 | 0.378440     | 4.526288e-04 | 0.011301 | 0.000259 | 0.060473      | 0.003149 |
| 00025358d4737918 | 0.091852     | 1.909959e-05 | 0.001575 | 0.000044 | 0.013020      | 0.000282 |
| 00026d1092fe71cc | 0.000122     | 9.204307e-07 | 0.000011 | 0.000002 | 0.000006      | 0.000003 |

在这一部分，你需要用可视化的方式展示项目中需要强调的重要技术特性。至于什么形式，你可以自由把握，但需要表达出一个关于这个项目重要的结论和特点，并对此作出讨论。一些需要考虑的：

- _你是否对一个与问题，数据集，输入数据，或结果相关的，重要的技术特性进行了可视化？_
- _可视化结果是否详尽的分析讨论了？_
- _绘图的坐标轴，标题，基准面是不是清晰定义了？_


### 对项目的思考
在这一部分，你需要从头到尾总结一下整个问题的解决方案，讨论其中你认为有趣或困难的地方。从整体来反思一下整个项目，确保自己对整个流程是明确掌握的。需要考虑：
- _你是否详尽总结了项目的整个流程？_
- _项目里有哪些比较有意思的地方？_
- _项目里有哪些比较困难的地方？_
- _最终模型和结果是否符合你对这个问题的期望？它可以在通用的场景下解决这些类型的问题吗？_


### 需要作出的改进
在这一部分，你需要讨论你可以怎么样去完善你执行流程中的某一方面。例如考虑一下你的操作的方法是否可以进一步推广，泛化，有没有需要作出变更的地方。你并不需要确实作出这些改进，不过你应能够讨论这些改进可能对结果的影响，并与现有结果进行比较。一些需要考虑的问题：
- _是否可以有算法和技术层面的进一步的完善？_
- _是否有一些你了解到，但是你还没能够实践的算法和技术？_
- _如果将你最终模型作为新的基准，你认为还能有更好的解决方案吗？_

----------
** 在提交之前， 问一下自己... **

- 你所写的项目报告结构对比于这个模板而言足够清晰了没有？
- 每一个部分（尤其**分析**和**方法**）是否清晰，简洁，明了？有没有存在歧义的术语和用语需要进一步说明的？
- 你的目标读者是不是能够明白你的分析，方法和结果？
- 报告里面是否有语法错误或拼写错误？
- 报告里提到的一些外部资料及来源是不是都正确引述或引用了？
- 代码可读性是否良好？必要的注释是否加上了？
- 代码是否可以顺利运行并重现跟报告相似的结果？

```
Epoch 1/10
 - 493s - loss: 0.0620 - acc: 0.9784 - val_loss: 0.0464 - val_acc: 0.9826

 ROC-AUC - epoch: 1 - score: 0.978826
Epoch 2/10
 - 390s - loss: 0.0456 - acc: 0.9826 - val_loss: 0.0439 - val_acc: 0.9823

 ROC-AUC - epoch: 2 - score: 0.984140
Epoch 3/10
 - 390s - loss: 0.0423 - acc: 0.9836 - val_loss: 0.0408 - val_acc: 0.9838

 ROC-AUC - epoch: 3 - score: 0.986708
Epoch 4/10
 - 390s - loss: 0.0399 - acc: 0.9843 - val_loss: 0.0405 - val_acc: 0.9841

 ROC-AUC - epoch: 4 - score: 0.987605
Epoch 5/10
 - 388s - loss: 0.0382 - acc: 0.9849 - val_loss: 0.0403 - val_acc: 0.9841

 ROC-AUC - epoch: 5 - score: 0.989321
Epoch 6/10
 - 387s - loss: 0.0364 - acc: 0.9854 - val_loss: 0.0396 - val_acc: 0.9841

 ROC-AUC - epoch: 6 - score: 0.989072
Epoch 7/10
 - 387s - loss: 0.0345 - acc: 0.9862 - val_loss: 0.0429 - val_acc: 0.9833

 ROC-AUC - epoch: 7 - score: 0.988589
Epoch 8/10
 - 387s - loss: 0.0330 - acc: 0.9867 - val_loss: 0.0409 - val_acc: 0.9841

 ROC-AUC - epoch: 8 - score: 0.988913
Epoch 9/10
 - 387s - loss: 0.0314 - acc: 0.9872 - val_loss: 0.0420 - val_acc: 0.9840

 ROC-AUC - epoch: 9 - score: 0.988839
Epoch 10/10
 - 387s - loss: 0.0304 - acc: 0.9877 - val_loss: 0.0416 - val_acc: 0.9835

 ROC-AUC - epoch: 10 - score: 0.988557
```

